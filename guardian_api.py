## ------------------------------------------------------------------ ##

import json 
import requests

## ------------------------------------------------------------------ ##

with open('api_keys.json') as f:
	api_key = json.load(f)['guardian_api_key']

## ------------------------------------------------------------------ ##

def return_url(section, start_date, end_date, page_size, api_key):
	api_url = ['http://content.guardianapis.com/search'
			   '?section=', section, 
			   '&from-date=', start_date,
			   '&to-date=', end_date,
			   '&page-size=', page_size, 
			   '&api-key=', api_key]
	return ''.join(api_url)

## ------------------------------------------------------------------ ##
## can only request 200 at a time

date_list = [('2015-01-01','2015-01-07'),
			 ('2015-01-08','2015-01-14'),
			 ('2015-01-15','2015-01-21'),
			 ('2015-01-22','2015-01-28'),
			 ('2015-01-29','2015-02-04'),
			 ('2015-02-05','2015-02-11'),
			 ('2015-02-12','2015-02-18'),
			 ('2015-02-19','2015-02-25'),
			 ('2015-02-26','2015-03-04'),
			 ('2015-03-05','2015-03-11'),
			 ('2015-03-12','2015-03-18'),
			 ('2015-03-19','2015-03-25'),
			 ('2015-03-26','2015-04-01'),
			 ('2015-04-02','2015-04-08'),
			 ('2015-04-09','2015-04-15'),
			 ('2015-04-16','2015-04-22'),
			 ('2015-04-23','2015-04-29'),
			 ('2015-04-30','2015-05-06'),
			 ('2015-05-07','2015-05-13'),
			 ('2015-05-14','2015-05-20'),
			 ('2015-05-21','2015-05-27'),
			 ('2015-05-28','2015-06-03'),
			 ('2015-06-04','2015-06-10'),
			 ('2015-06-11','2015-06-17'),
			 ('2015-06-18','2015-06-24'),
			 ('2015-06-25','2015-07-01'),
			 ('2015-07-02','2015-07-08'),
			 ('2015-07-09','2015-07-15'),
			 ('2015-07-16','2015-07-22'),
			 ('2015-07-23','2015-07-29'),
			 ('2015-07-30','2015-08-05'),
			 ('2015-08-06','2015-08-12'),
			 ('2015-08-13','2015-08-19'),
			 ('2015-08-20','2015-08-26'),
			 ('2015-08-27','2015-09-02')]

## ------------------------------------------------------------------ ##
## get the article data 

content = []
for date_tuple in date_list:
	url = return_url('us-news', date_tuple[0], date_tuple[1], '200', api_key)
	r = requests.get(url)
	content.append(r.content)

## ------------------------------------------------------------------ ##
## clean, flatten and write to file 

content = [json.loads(x)['response']['results'] for x in content]
content = [x for sublist in content for x in sublist]

with open('guardian_results_us_news_2015.txt', 'wb') as f:
	json.dump(content, f)
	f.close() 

## ------------------------------------------------------------------ ##
